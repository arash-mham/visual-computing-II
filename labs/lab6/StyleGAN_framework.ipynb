{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qi6YsQV_yoPN"
      },
      "outputs": [],
      "source": [
        "#@title Setup model\n",
        "\n",
        "import os\n",
        "os.chdir('/content')\n",
        "\n",
        "!unzip stylegan2.zip\n",
        "\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title import modules\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "%pip install -q ipywidgets\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "\n",
        "from stylegan2.model import Generator"
      ],
      "metadata": {
        "id": "Q_NZcAj0zNsz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download checkpoint\n",
        "#@title Setup files downloader\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "download_with_pydrive = True \n",
        "\n",
        "CODE_DIR = ''\n",
        "class Downloader(object):\n",
        "    def __init__(self, use_pydrive):\n",
        "        self.use_pydrive = use_pydrive\n",
        "        current_directory = os.getcwd()\n",
        "        self.save_dir = os.path.join(os.path.dirname(current_directory), CODE_DIR, \"pretrained_models\")\n",
        "        os.makedirs(self.save_dir, exist_ok=True)\n",
        "        print(self.save_dir)\n",
        "        if self.use_pydrive:\n",
        "            self.authenticate()\n",
        "\n",
        "    def authenticate(self):\n",
        "        auth.authenticate_user()\n",
        "        gauth = GoogleAuth()\n",
        "        gauth.credentials = GoogleCredentials.get_application_default()\n",
        "        self.drive = GoogleDrive(gauth)\n",
        "\n",
        "    def download_file(self, file_id, file_name):\n",
        "        file_dst = f'{self.save_dir}/{file_name}'\n",
        "        if os.path.exists(file_dst):\n",
        "            print(f'{file_name} already exists!')\n",
        "            return\n",
        "        if self.use_pydrive:\n",
        "            downloaded = self.drive.CreateFile({'id':file_id})\n",
        "            downloaded.FetchMetadata(fetch_all=True)\n",
        "            downloaded.GetContentFile(file_dst)\n",
        "        else:\n",
        "            !gdown --id $file_id -O $file_dst\n",
        "\n",
        "downloader = Downloader(download_with_pydrive)\n",
        "id = '1EM87UquaoQmk17Q8d5kYIAHqu0dkYqdT'\n",
        "file_name = 'stylegan2-ffhq-config-f.pt'\n",
        "\n",
        "downloader.download_file(id, file_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY4ToMXvz3-q",
        "outputId": "1450898f-2a17-47e9-8953-c3684358895c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/pretrained_models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator_Wrapper:\n",
        "  def __init__(self):\n",
        "    self.model = Generator(1024, 512, 8).to('cuda')\n",
        "    self.init_weights()\n",
        "    self.face_pool = torch.nn.AdaptiveAvgPool2d((256, 256))\n",
        "  def init_weights(self):\n",
        "    self.model.load_state_dict(torch.load('../pretrained_models/stylegan2-ffhq-config-f.pt')['g_ema'])\n",
        "\n",
        "  def generate_image(self, input = None, input_is_latent = False, num_images = 1):\n",
        "    if input is None:\n",
        "      input = torch.randn((num_images, 512)).cuda()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      out, latents = self.model([input], input_is_latent = input_is_latent, return_latents = True)\n",
        "      out = self.face_pool(out)\n",
        "      return out, latents\n",
        "\n",
        "  def tensor2image(self, out):\n",
        "    #TODO: given tensor of size (B, 3, 256, 256) in the range(-1, 1) return a PIL Image with size (256, 256 * B, 3)\n",
        "    "
      ],
      "metadata": {
        "id": "uKriRUgs1BiA"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = Generator_Wrapper()\n",
        "images, latents = G.generate_image(num_images = 4)"
      ],
      "metadata": {
        "id": "JdiySyDM2dny"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G.tensor2image(images)"
      ],
      "metadata": {
        "id": "bj0Ne8vg3TOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Latent interpolation\n",
        "\n",
        "#TODO: generate two images with latents and visualize"
      ],
      "metadata": {
        "id": "2eHRcBs846bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#interpolate two latents\n",
        "def interpolate_latents(interpolate_scale):\n",
        "  #TODO: interpolate between two latents generated above. interpolate_scale is the interpolation coefficient\n",
        "\n",
        "  res = Image.fromarray(np.zeros((256, 256, 3)).astype('uint8'))\n",
        "  return res"
      ],
      "metadata": {
        "id": "jxN7xYpO5O53"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make slider and show\n",
        "interact(interpolate_latents, interpolate_scale=widgets.FloatSlider(0.5, min=0, max=1., step=0.05))"
      ],
      "metadata": {
        "id": "it9E0GZi5tcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mixing latents\n",
        "\n",
        "#TODO: make a base image with latents and show"
      ],
      "metadata": {
        "id": "Iuz1drLO6uGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: make 3 new faces. They will be edited using base latent"
      ],
      "metadata": {
        "id": "SeWO3Z-87Fgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mix_latents(mixing_point):\n",
        "  #TODO: mix latents. the first mixing_point blocks should get the latent from base_latent and the rest come from target_latents\n",
        "  #edited_latents = ...\n",
        "  edited_images, _ = G.generate_image(edited_latents, input_is_latent = True)\n",
        "  return G.tensor2image(edited_images)\n",
        " "
      ],
      "metadata": {
        "id": "HHpK34JP7RN-"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interact(mix_latents, mixing_point=widgets.IntSlider(0, min=0, max=18, step=1))"
      ],
      "metadata": {
        "id": "mNZKses37q7v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}